all = rbind(all,temp)
}
View(all)
look = all %>%
group_by(SPECIES_SCIENTIFIC, lockedin,features)%>%
summarise(mean(target_achieved),
mean(absolute_held_avg))
View(look)
look = all %>%
group_by(lockedin,features,costs)%>%
summarise(mean(target_achieved),
mean(absolute_held_avg),
sd(target_achieved),
sd(absolute_held_avg),  )
View(look)
look = all %>%
group_by(lockedin,features,costs)%>%
summarise(mean(target_achieved),
(mean(absolute_held_avg)/10809)*100,
sd(target_achieved),
sd(absolute_held_avg),  )
View(all)
mean(absolute_held_avg,
View(look)
View(look)
library(biomod2)
?BIOMOD_FormatingData
?BIOMOD_Modeling
# ---------------------------------
# PACKAGES
# ---------------------------------
# list of required packages
requiredpackages = c("devtools","readxl","viridis","devtools","fuzzySim","dismo","rgdal","rgeos","sf","rasterVis","ggplot2","raster","stringr","readxl", "raster", "sp", "dplyr", "lubridate")
# check which packages you need to install
requiredpackages = requiredpackages[which(!(requiredpackages %in% installed.packages()))]
# install packages
install.packages(requiredpackages)
# list of required packages
requiredpackages = c("devtools","readxl","viridis","devtools","fuzzySim","dismo","rgdal","rgeos","sf","rasterVis","ggplot2","raster","stringr","readxl", "raster", "sp", "dplyr", "lubridate")
# load packages
lapply(requiredpackages,require, character.only = TRUE)
# intsall latest version of biomod2
devtools::install_github("biomodhub/biomod2", dependencies = TRUE)
# ---------------------------------
# DEFINE WORKING DIRECTORY
# ---------------------------------
# set directory to same parent folder where sub-scripts are found
# the subs-scripts can be in folders within this directory as the code will look through all the folders
my.directory = getwd()
# set directory
setwd(my.directory)
# ---------------------------------
#  - ENVIRONMENTAL VARIABLES
# ---------------------------------
# specify model resolution
# we chose between a grid of 5 x 5 km (res = 5) or 10 x 10 km (res = 10)
res = 10
source(list.files(pattern = "envnt_variable_stack.R", recursive = TRUE, full.names = TRUE))
# ---------------------------------
#  SPECIES SPECIFIC MODEL PARAMETERS
# ---------------------------------
# read master file with species-specific modelling parameters
# this sheet contains a list of all species with some additional data details
master = read_xlsx(list.files(pattern = "data_summary_master.xlsx", recursive = TRUE,full.names = TRUE))
View(master)
# filter master sheet to keep species with a minimum prevalence of 1
# the prevalence value indicates how much data there is for this species relative to entire modeling surface
# i.e. it is the percentage of cells with data out of total cells, so the lower your resolution, the higher the prevalence
if(res ==10){
master_keep = master %>%
filter(prevalence_10 >=0.01)}
# IMPORTANT: to run the loop with the example data make sure exampledata = "yes"
exampledata = "no"
i=1
# MODEL PARAMATERS
target = master_keep$SPECIES_SCIENTIFIC[i] # species name
substrate = master_keep$Substrate[i] # specifies if substrate layer is to be included
seasonal = "no"
# OCCURRENCE DATA
source(list.files(pattern = "species_data.R", recursive = TRUE, full.names = TRUE))
# OCCURRENCE DATA
source(list.files(pattern = "species_data.R", recursive = TRUE, full.names = TRUE))
# file name
FILENAME = paste(toupper(target),".rds",sep="")
# identifies location of occurrence file on computer
file = list.files(pattern = FILENAME,recursive = TRUE, full.names = TRUE)
FILENAME
list.files(pattern = FILENAME,recursive = TRUE, full.names = TRUE)
getwd()
str_remove(my.directory,"/wildoceans-scripts")
# identifies location of occurrence file on computer
file = list.files(path =str_remove(my.directory,"/wildoceans-scripts"),pattern = FILENAME,recursive = TRUE, full.names = TRUE)
# ---------------------------------
# FORMATTING
# ---------------------------------
# not all species from master sheet have data
# this if statement runs the script only if the target species has associated data
if(length(file)>0){
# load in data file
if(str_detect(file,".csv")){obs.data = read.csv(file)}else{obs.data = readRDS(file)}
# convert latitude and longitude to numeric variables
obs.data$LONGITUDE = as.numeric(obs.data$LONGITUDE)
obs.data$LATITUDE = as.numeric(obs.data$LATITUDE)
# convert column names to upper
colnames(obs.data) = toupper(colnames(obs.data))
# this if statement further ensures that the script should only by run if the dataframe has any data
if(nrow(obs.data)>0){
# verify there are no NAs in latitude and longitude
# if there are a warning message will appear
if(unique(!is.na(obs.data$LATITUDE)) == FALSE){
print("SOME NAs ARE PRESENT IN THE LATITUDE DATA")}
if(unique(!is.na(obs.data$LONGITUDE)) == FALSE){
print("SOME NAs ARE PRESENT IN THE LONGITUDE DATA")}
# remove any 0 latitude and longitude
obs.data = obs.data %>%
filter(LONGITUDE != 0) %>%
filter(LATITUDE != 0)
# verify duplicates (for latitude, longitude, and date)
dups = duplicated(obs.data[c("LATITUDE","LONGITUDE", "DATE")])
# print number of duplicate records, TRUE are number of duplicates
print(table(dups))
# remove duplicates from data
obs.data = obs.data[!dups,]
rm(dups)
# save number of occurrence points as variable
abundance = nrow(obs.data)
# add month variable from Date
obs.data = obs.data %>%
mutate(MONTH = month(obs.data$DATE))
# check for seasonality column
if(!"SEASON" %in% colnames(obs.data)){obs.data$SEASON = NA}
# group observations by season
# important: some datasets came with season already specified
obs.data = obs.data %>%
# if SEASON variable is empty, convert to NA
mutate(SEASON = ifelse(SEASON == "",NA,SEASON)) %>%
# specify winter months
mutate(SEASON = ifelse(is.na(SEASON) & MONTH %in% c(3,4,5,6,7,8),"Winter",
# specify summer months
ifelse(is.na(SEASON) & MONTH %in% c(9,10,11,12,1,2), "Summer",
# if season was stated as autumn then turn to winter
ifelse(SEASON == "Autumn","Winter",
# if season was stated as spring then turn to summer
ifelse(SEASON == "Spring","Summer",SEASON)))))
# convert data to spatial points data frame
coordinates(obs.data) =  ~ cbind(obs.data$LONGITUDE,obs.data$LATITUDE)
# this prevents the loop running through on multiple species name with the same example file
if(unique(obs.data$SPECIES_SCIENTIFIC) != target){print("SPECIES NAME IN MASTER SHEET AND IN DATA DO NOT MATCH")}
}else{length(file) = 0}}
View(obs.data)
ncell(stack_subset)
?cellFromXY
cellFromXY(stack_subset,obs.data)
plot(obs.data)
plot(obs.data@proj4string)
plot(obs.data@coords.nrs)
plot(obs.data@coords)
cellFromXY(stack_subset,obs.data)
length(cellFromXY(stack_subset,obs.data))
obs.data$cellid = cellFromXY(stack_subset,obs.data)
View(obs.data)
range(obs.data$DATE)
obs.data$DATE
range(obs.data$DATE, na.rm = T)
obs.data %>%
group_by(cellid)%>%
summarise()
obs.data@data %>%
group_by(cellid)%>%
summarise()
obs.data@data %>%
group_by(cellid)%>%
summarise(min(DATE))
obs.data@data %>%
group_by(cellid)%>%
summarise(max(DATE))
obs.data@data %>%
group_by(cellid)%>%
summarise(n(),
max(DATE))
obs.data@data %>%
group_by(cellid)%>%
summarise(n(),
max(DATE),
min(DATE))
pts_sub = SpatialPoints(gridSample(obs.data, stack_subset, n=1),bbox =  bbox(stack_subset))
View(pts_sub)
obs.data@data %>%
group_by(cellid)%>%
summarise(n(),
max(DATE))
obs.data@data %>%
group_by(cellid)%>%
summarise(n(),
max(DATE))%>%
filter(!is.na(cellid))
# get most recent date for each grid cell with data point
obs.data@data %>%
group_by(cellid)%>%
summarise(max(DATE))%>%
filter(!is.na(cellid))
?gridSample
gridSample(obs.data, stack_subset, n=1)
# get most recent date for each grid cell with data point
presencecells = obs.data@data %>%
group_by(cellid)%>%
summarise(max(DATE))%>%
filter(!is.na(cellid))
xyFromCell(stack_subset,presencecells)
stack_subset
xyFromCell(stack_subset,presencecells$cellid)
SpatialPoints(xyFromCell(stack_subset,presencecells$cellid))
pts_sub
plot(pts_sub)
plot(pts_sub@coords)
# create spatial points object from presence cell ids
pts_sub = SpatialPoints(xyFromCell(stack_subset,presencecells$cellid))
plot(pts_sub@coords)
scale(presencecells$`max(DATE)`)
?scale
plot(scale(presencecells$`max(DATE)`))
plot(scale(presencecells$`max(DATE)`), scale=TRUE)
plot(scale(presencecells$`max(DATE)`,scale=TRUE))
plot(rescale(presencecells$`max(DATE)`))
# get most recent date for each grid cell with data point
presencecells = obs.data@data %>%
group_by(cellid)%>%
summarise(date_recent = max(DATE))%>%
filter(!is.na(cellid))
apply(presencecells$date_recent,MARGIN=2,FUN=function(x) (x-min(x))/diff(range(x)))
presencecells$date_recent
apply(presencecells$date_recent,MARGIN=1,FUN=function(x) (x-min(x))/diff(range(x)))
install.packages("scales")
library(scales)
rescale(presencecells$date_recent)
plot(rescale(presencecells$date_recent))
View(master_keep)
View(master)
target = "GALEOCERDO CUVIER"
# OCCURRENCE DATA
source(list.files(pattern = "species_data.R", recursive = TRUE, full.names = TRUE))
# assign grid cell id to each data point
obs.data$cellid = cellFromXY(stack_subset,obs.data)
# get most recent date for each grid cell with data point
presencecells = obs.data@data %>%
group_by(cellid)%>%
summarise(date_recent = max(DATE))%>%
filter(!is.na(cellid))
presencecells
# create spatial points object from presence cell ids
pts_sub = SpatialPoints(xyFromCell(stack_subset,presencecells$cellid))
plot(rescale(presencecells$date_recent))
scaled_date = rescale(presencecells$date_recent)
# add to presence cells
cbind(presencecells,scaled_date)
# add to presence cells
presencecells= cbind(presencecells,scaled_date)
pts_sub$scaled_date = scaled_date
library(RColorBrewer)
plot(pts_sub@proj4string)
plot(pts_sub@coords)
brewer.pal(4,"blues")
brewer.pal(4,"Blues")
cols = brewer.pal(4,"Blues")
pal = colorRampPalette(cols)
pts_sub$order = findInterval(pts_sub$scaled_date,sort(pts_sub$scaled_date))
plot(pts_sub@coords,pch=19,col=pal(nrow(pts_sub))[pts_sub$order])
legend("topright",col=pal(2),pch=19)
legend("topright",col=pal(2),pch=19,legend = c(round(range(pts_sub$scaled_date),1)))
# set crs to match that of environmental variables
crs(pts_sub) = crs(stack_subset)
0.2*length(which(values(!is.na(stack_subset[[1]]))))
# ---------------------------------
# FORMATTING
# ---------------------------------
# pick number of background points to choose from during model development (we went with 10,000 points)
# pseudo-absences choice procedure: Barbet-Messin et al., 2012
n_bckg_pts = 10000
# isolate these n background points randomly across all cells in the EEZ using randomPoints()
cells = randomPoints(stack_subset, n_bckg_pts,cellnumbers=TRUE, ext = extent(stack_subset))
# get xy coordinates from these cells
absences = SpatialPoints(xyFromCell(stack_subset[[1]],cells),bbox =  bbox(stack_subset))
# set crs to match occurrence points
crs(absences) = crs(pts_sub)
# combine presences and background points in single object
# object names pa from presenceabsence even though they are not true absences
pa = rbind(pts_sub,absences)
# add slot for weights
absences$scaled_date =NA
absences
# add slot for weights
absences$scaled_date = 1
absences
absences$scaled_date
# add slot for weights
absences$scaled_date = 1
# add slot for weights
absences$scaled_date = rep(1,length(absences))
# combine presences and background points in single object
# object names pa from presenceabsence even though they are not true absences
pa = rbind(pts_sub,absences)
pts_sub
absences
# remove order variable
pts_sub$order=NULL
# combine presences and background points in single object
# object names pa from presenceabsence even though they are not true absences
pa = rbind(pts_sub,absences)
# create a data frame
# add column of 1s and 0s for presences and background points respectively
pa = as.data.frame(c(rep(1,length(pts_sub)),rep(0,length(absences))))
pa
# rename that column pa (for presence absence)
colnames(pa) = "pa"
# add coordinates to data frame
pa = cbind(pa,rbind(coordinates(pts_sub),coordinates(absences)))
# rename columns
colnames(pa)[c(2,3)] = c("LONGITUDE","LATITUDE")
# extract environmental values from raster stack at coordinates of presence and background points
vars = as.data.frame(raster::extract(stack_subset, pa[,c(2,3)]))
# add to dataframe
pts_env = cbind(pa,vars)
# this allows you to see the default model parameters used by biomod
bm_DefaultModelingOptions() # these are the default parameters used for each model
# default parameters can be altered using BIOMOD_ModelingOptions()
# in our case we will be using MAXENT so i need to specify the path to my downloaded MAXENT file
# i also want to specify the use of a polynomial GLM
mxtPh = BIOMOD_ModelingOptions(MAXENT = list(path_to_maxent.jar = paste0(my.directory,"/maxent"),
maximumiterations = 400),
GLM = list(type = 'polynomial'),
GAM = list(control = list(nlm = list(iterlim = 400))))
# ---------------------------------
# PACKAGES
# ---------------------------------
# biomod2 is loaded in separately as it interacts with functions from other packages
detach(package:dismo,unload=TRUE)
library(biomod2)
# this allows you to see the default model parameters used by biomod
bm_DefaultModelingOptions() # these are the default parameters used for each model
# default parameters can be altered using BIOMOD_ModelingOptions()
# in our case we will be using MAXENT so i need to specify the path to my downloaded MAXENT file
# i also want to specify the use of a polynomial GLM
mxtPh = BIOMOD_ModelingOptions(MAXENT = list(path_to_maxent.jar = paste0(my.directory,"/maxent"),
maximumiterations = 400),
GLM = list(type = 'polynomial'),
GAM = list(control = list(nlm = list(iterlim = 400))))
# remove NAs
pts_env = na.omit(pts_env)
# isolate presence/background points column of 1s and 0s
pa = pts_env$pa
pts_env
# combine presences and background points in single object
# object names pa from presenceabsence even though they are not true absences
pa = rbind(pts_sub,absences)
# extract weights
weights = pa$scaled_date
weights
pts_env
# create a data frame
# add column of 1s and 0s for presences and background points respectively
pa = as.data.frame(c(rep(1,length(pts_sub)),rep(0,length(absences))))
# rename that column pa (for presence absence)
colnames(pa) = "pa"
# add coordinates to data frame
pa = cbind(pa,rbind(coordinates(pts_sub),coordinates(absences)))
# rename columns
colnames(pa)[c(2,3)] = c("LONGITUDE","LATITUDE")
# extract environmental values from raster stack at coordinates of presence and background points
vars = as.data.frame(raster::extract(stack_subset, pa[,c(2,3)]))
# add to dataframe
pts_env = cbind(pa,vars)
# add weights (scaled date)
pts_env$weights = weights
# remove NAs
pts_env = na.omit(pts_env)
# isolate presence/background points column of 1s and 0s
pa = pts_env$pa
# convert 0 to NAs
# this is important as it means they are seen as background points and not true absences
pa[which(pa == 0)] = NA
# isolate presence/background points coordinates
pa_xy = pts_env[,c(2,3)]
length(pts_env)
# isolate environmental variables columns (from column 4 onwards)
exp =  pts_env[,-c(1:3,length(pts_env))]
table(pa)
is.na(pa)
# from all your generated background points in the pseudo-absence script
# pick the same number as your number of presence points
# this is because for each model run we chose to have the same number of presences as number of background points
# and we run each model with 2 sets of background points (specified by PA.nb.rep = 2)
pseudoabsences = length(which(is.na(pa)))
# make sure substrate is a factor
exp$substrate_simplified = as.factor(exp$substrate_simplified)
!is.na(substrate) & substrate == "no"
# keep or remove substrate layer
if(!is.na(substrate) & substrate == "no"){
stack_model = dropLayer(stack_subset,"substrate_simplified")
exp$substrate_simplified = NULL}else{stack_model = stack_subset}
length(which(pa==1))<100
# reduce number of environmental variables if prevalence is less than 100 grid cells
if(length(which(pa==1))<100){
reducedvar = read.csv(list.files(pattern = "reducedvariables.csv", recursive=TRUE, full.names = TRUE))
stack_model = dropLayer(stack_model,reducedvar$x)
exp = exp[,which(!(colnames(exp) %in% reducedvar$x))]
rm(reducedvar)}
list.files(pattern = "reducedvariables.csv", recursive=TRUE, full.names = TRUE)
exp
pseudoabsences
# biomod object
biomod_obj =  BIOMOD_FormatingData(resp.var = pa, # presence/background data
expl.var = exp, # environmental variables
resp.xy = pa_xy, # response variable coordinates
resp.name = target, # species name
# this will pick the pseudo-absences from your NAs in pa
PA.nb.absences = pseudoabsences,
# two sets of pseudoabsences to be chosen
PA.nb.rep = 1,
# for high specificity pseudo-absences should be randomly selected
PA.strategy = 'random')
weights
length(weights)
# weights
weights = pts_env$weights
weights
# biomod object
biomod_obj =  BIOMOD_FormatingData(resp.var = pa, # presence/background data
expl.var = exp, # environmental variables
resp.xy = pa_xy, # response variable coordinates
resp.name = target, # species name
# this will pick the pseudo-absences from your NAs in pa
PA.nb.absences = pseudoabsences,
# two sets of pseudoabsences to be chosen
PA.nb.rep = 1,
# for high specificity pseudo-absences should be randomly selected
PA.strategy = 'random')
static_models <- BIOMOD_Modeling(
data, # your biomod object
#var.import = 5,
models = c('GAM','GLM','MAXENT.Phillips'), # 3 modelling algorithms run for project
bm.options  = mxtPh, # modified model parameters, unnecessary if you are happy with default biomod2 parameters
nb.rep = 1, # 10-fold cross validation (number of evaluations to run)
data.split.perc = 75, # 75% of data used for calibration, 25% for testing
metric.eval  = c('TSS'), # evaluation method, TSS is True Statistics Skill
save.output  = TRUE, # keep all results on hard drive
scale.models = FALSE, # if true, all model prediction will be scaled with a binomial GLM
modeling.id = target, # name of model = species name (target)
nb.cpu = 8,
weights = weights
)
# ASEASONAL MODEL RUNS AND PROJECTIONS
model_type = "Aseasonal" # specify model_type
data = biomod_obj # specify which biomod_obj
static_models <- BIOMOD_Modeling(
data, # your biomod object
#var.import = 5,
models = c('GAM','GLM','MAXENT.Phillips'), # 3 modelling algorithms run for project
bm.options  = mxtPh, # modified model parameters, unnecessary if you are happy with default biomod2 parameters
nb.rep = 1, # 10-fold cross validation (number of evaluations to run)
data.split.perc = 75, # 75% of data used for calibration, 25% for testing
metric.eval  = c('TSS'), # evaluation method, TSS is True Statistics Skill
save.output  = TRUE, # keep all results on hard drive
scale.models = FALSE, # if true, all model prediction will be scaled with a binomial GLM
modeling.id = target, # name of model = species name (target)
nb.cpu = 8,
weights = weights
)
static_models <- BIOMOD_Modeling(
data, # your biomod object
#var.import = 5,
models = c('GAM','GLM','MAXENT.Phillips'), # 3 modelling algorithms run for project
bm.options  = mxtPh, # modified model parameters, unnecessary if you are happy with default biomod2 parameters
nb.rep = 1, # 10-fold cross validation (number of evaluations to run)
data.split.perc = 75, # 75% of data used for calibration, 25% for testing
metric.eval  = c('TSS'), # evaluation method, TSS is True Statistics Skill
save.output  = TRUE, # keep all results on hard drive
scale.models = FALSE, # if true, all model prediction will be scaled with a binomial GLM
modeling.id = target, # name of model = species name (target)
nb.cpu = 8,
#weights = weights
)
# biomod object
biomod_obj =  BIOMOD_FormatingData(resp.var = pa, # presence/background data
expl.var = exp, # environmental variables
resp.xy = pa_xy, # response variable coordinates
resp.name = target, # species name
# this will pick the pseudo-absences from your NAs in pa
PA.nb.absences = 100,
# two sets of pseudoabsences to be chosen
PA.nb.rep = 1,
# for high specificity pseudo-absences should be randomly selected
PA.strategy = 'random')
# ASEASONAL MODEL RUNS AND PROJECTIONS
model_type = "Aseasonal" # specify model_type
data = biomod_obj # specify which biomod_obj
static_models <- BIOMOD_Modeling(
data, # your biomod object
#var.import = 5,
models = c('GAM','GLM','MAXENT.Phillips'), # 3 modelling algorithms run for project
bm.options  = mxtPh, # modified model parameters, unnecessary if you are happy with default biomod2 parameters
nb.rep = 1, # 10-fold cross validation (number of evaluations to run)
data.split.perc = 75, # 75% of data used for calibration, 25% for testing
metric.eval  = c('TSS'), # evaluation method, TSS is True Statistics Skill
save.output  = TRUE, # keep all results on hard drive
scale.models = FALSE, # if true, all model prediction will be scaled with a binomial GLM
modeling.id = target, # name of model = species name (target)
nb.cpu = 8,
#weights = weights
)
data
mxtPh
data
